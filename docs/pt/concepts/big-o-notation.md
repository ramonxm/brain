# NotaÃ§Ã£o Big O

### Big O **fala sobre como os algoritmos ESCALAM** dependendo do **tamanho** da **entrada**, e **nÃ£o** necessariamente sobre o **desempenho** do **algoritmo**.

<aside>
ğŸ’¡

Ã‰ uma forma de **denotar o desempenho do algoritmo**, mas **nÃ£o** Ã© uma **medida de desempenho**

</aside>

<aside>
ğŸ’¡

Big O **nÃ£o mede o tempo exato de execuÃ§Ã£o** de um algoritmo, mas sim **como o tempo cresce** conforme o tamanho da entrada aumenta. ğŸ“ˆ

</aside>

---

### Big O pode ser usado para medir tanto a *complexidade de tempo* quanto a *complexidade de espaÃ§o* de um algoritmo.

- **Complexidade de Tempo**: Relaciona-se ao tempo de execuÃ§Ã£o (runtime), ou seja, quanto tempo leva para executar. **Mais comum em entrevistas**
- **Complexidade de EspaÃ§o**: Relaciona-se a quanto de memÃ³ria adicional precisamos alocar

---

> A **anÃ¡lise assintÃ³tica** Ã© a forma de analisar como um algoritmo se comporta em termos de tempo e memÃ³ria conforme o tamanho da entrada cresce.
> 

---

# Principais notaÃ§Ãµes do BIG O:

## **O(1) â€“ Complexidade Constante â†’**

> *"Acender uma luz com um interruptor â€“ sempre leva o mesmo tempo, independente do tamanho da casa."*
> 
- **ğŸ§  Explicado usando a TÃ©cnica Feynman**
    
    Imagine que vocÃª tem uma caixa de objetos e precisa encontrar um item especÃ­fico nela. Agora, em vez de procurar em cada item da caixa, vocÃª jÃ¡ sabe exatamente onde ele estÃ¡. Ao abrir a caixa, vocÃª vai diretamente ao item certo, sem precisar verificar nada mais. 
    O tempo que vocÃª leva para encontrar o item Ã© o mesmo, nÃ£o importa quantos itens estejam na caixa. Isso Ã© o que acontece com a complexidade **O(1)**. 
    Independentemente do tamanho da entrada, o tempo de execuÃ§Ã£o do algoritmo Ã© constante.
    
    **O(1)** Ã© complexidade constante, significando que o tempo de execuÃ§Ã£o do algoritmo nÃ£o depende do tamanho da entrada. Independentemente de quantos elementos existam, o tempo ou memÃ³ria consumidos sÃ£o os mesmos.
    
- **ğŸ§ Exemplo PrÃ¡tico**
    - Acessar o primeiro elemento de um array: `arr[0]`
    - Verificar se um nÃºmero Ã© par: `num % 2 == 0`
    - Inserir ou remover um item do topo de uma pilha
- **â° Sobre Complexidade Temporal**
    
    **Tempo constante**, significando que independentemente do tamanho da entrada, o algoritmo tem o mesmo tempo de execuÃ§Ã£o.
    
    O tempo de execuÃ§Ã£o nÃ£o muda, seja o tamanho da entrada pequeno ou grande. O algoritmo sempre leva o mesmo tempo para executar.
    
    **â° Exemplos de O(1) â€“ Tempo**
    
    - Acessar um Ã­ndice especÃ­fico do array â†’ *arr[0]*
    - Verificar se um nÃºmero Ã© par â†’ *num % 2 == 0*
    - Inserir/remover um elemento no topo de uma pilha
    - Exemplo de algoritmos O(1) â†’
        - Encontrar o primeiro elemento de um array
- **ğŸ‘©ğŸ¼â€ğŸš€ Sobre Complexidade Espacial**
    
    **MemÃ³ria constante**, significando que o espaÃ§o alocado nÃ£o cresce com a entrada.
    
    O espaÃ§o de memÃ³ria tambÃ©m nÃ£o varia com o tamanho da entrada. O algoritmo usa a mesma quantidade de memÃ³ria independentemente do nÃºmero de elementos.
    
    ğŸ’¾ **Exemplos de O(1) â€“ MemÃ³ria**
    
    - Criar uma variÃ¡vel e armazenar um valor fixo (int x = 10;)
    - Trocar valores de duas variÃ¡veis (a, b = b, a)
- **ğŸ” Como identificar se Ã© O(1)?**
    
    **Como identificar**:
    
    Se o algoritmo realiza uma Ãºnica operaÃ§Ã£o, independentemente do tamanho da entrada, Ã© **O(1)**. Em outras palavras, o nÃºmero de passos para completar a tarefa nÃ£o muda com o aumento da entrada.
    
    **Exemplo**:
    
    - Se vocÃª acessa um elemento do array diretamente, como `arr[5]`, ou troca valores de duas variÃ¡veis, o tempo para essas operaÃ§Ãµes Ã© constante.

---

## **O(log n) â€“ Complexidade LogarÃ­tmica â†’**

> *"Encontrar um nome na lista telefÃ´nica dividindo as pÃ¡ginas ao meio a cada vez."*
> 
- **ğŸ§  Explicado usando a TÃ©cnica Feynman**
    
    Imagine que vocÃª tem um livro com **1.000 pÃ¡ginas** e quer encontrar uma palavra especÃ­fica. Se vocÃª folhear pÃ¡gina por pÃ¡gina, do inÃ­cio ao fim, poderia levar muito tempo (O(n)).
    
    Agora, imagine um mÃ©todo mais inteligente: **vocÃª abre o livro no meio** e vÃª se a palavra estÃ¡ antes ou depois daquela pÃ¡gina. Se estiver antes, vocÃª ignora a metade de trÃ¡s e olha apenas a metade da frente. Se estiver depois, ignora a metade da frente e foca na metade de trÃ¡s.
    
    Repita este processo, cortando o problema pela metade a cada passo. Em muito poucos passos, vocÃª encontra a palavra! ğŸ¯
    
    ğŸ”¢ **Isso Ã© O(log n)** â†’ Em vez de processar **todos** os elementos, vocÃª reduz drasticamente a quantidade de verificaÃ§Ãµes.
    
- **ğŸ§ Exemplo PrÃ¡tico**
    - VocÃª tem um array ordenado e quer encontrar um nÃºmero.
    - Comece olhando o meio:
        - Se for o nÃºmero que procuramos, fim! ğŸ‰
        - Se o nÃºmero for menor, olhamos apenas a metade da esquerda.
        - Se for maior, olhamos apenas a metade da direita.
    - Em cada passo, cortamos o problema pela **metade** atÃ© encontrar o resultado.
- **â° Sobre Complexidade Temporal**
    
    O tempo de execuÃ§Ã£o cresce muito mais devagar Ã  medida que o tamanho da entrada aumenta, em comparaÃ§Ã£o com algoritmos **O(n)** ou **O(nÂ²)**.
    
    â° **Exemplos de O(log n) - Temporal**
    
    - **Busca binÃ¡ria**: A cada iteraÃ§Ã£o, o nÃºmero de elementos possÃ­veis Ã© reduzido pela metade.
    - **Encontrar o elemento no meio de uma lista ordenada** e eliminar metade das opÃ§Ãµes em cada iteraÃ§Ã£o.
- **ğŸ‘©ğŸ¼â€ğŸš€ Sobre Complexidade Espacial**
    
    A memÃ³ria utilizada por um algoritmo **O(log n)** tambÃ©m cresce de forma logarÃ­tmica em relaÃ§Ã£o ao tamanho da entrada. Isso significa que, mesmo que o nÃºmero de elementos cresÃ§a, o espaÃ§o utilizado por cada operaÃ§Ã£o nÃ£o aumenta drasticamente.
    
    **ğŸ‘©ğŸ¼â€ğŸš€ Exemplos de O(log n) - Espacial**
    
    - **RecursÃ£o em busca binÃ¡ria**, onde a pilha de chamadas cresce logaritmicamente Ã  medida que o tamanho da entrada diminui.
    - Algoritmos de **divisÃ£o e conquista** podem precisar de espaÃ§o extra para armazenar subproblemas, mas o espaÃ§o usado nÃ£o cresce linearmente.
- **ğŸ” Como identificar se Ã© O(log n)?**
    
    **Como identificar**:
    
    Se vocÃª perceber que, a cada passo, o tamanho do problema diminui significativamente â€” por exemplo, sempre pela metade â€” o algoritmo provavelmente tem complexidade **O(log n)**. Isso acontece porque o nÃºmero de iteraÃ§Ãµes necessÃ¡rias cresce muito mais devagar do que o tamanho da entrada.
    
    **Exemplo**:
    
    - Se vocÃª estÃ¡ dividindo o problema pela metade a cada iteraÃ§Ã£o, como em uma busca binÃ¡ria, o tempo de execuÃ§Ã£o serÃ¡ **O(log n)**.
    - Quando o algoritmo realiza uma busca ou divisÃ£o de dados que elimina metade das opÃ§Ãµes a cada passo, como na **busca binÃ¡ria**, vocÃª pode identificar que Ã© **O(log n)**.

---

## **O(n) â€“ Complexidade Linear â†’**

> *"Ler um livro do comeÃ§o ao fim sem pular pÃ¡ginas."*
> 
- **ğŸ§  Explicado usando a TÃ©cnica Feynman**
    
    Imagine que vocÃª tem uma fila de pessoas esperando para fazer uma tarefa. Se a pessoa na frente terminar, ela chama a prÃ³xima, e assim por diante, atÃ© que todos tenham feito a tarefa. O tempo necessÃ¡rio para todos fazerem a tarefa depende diretamente de quantas pessoas estÃ£o na fila. Se houver mais pessoas na fila, o tempo total aumenta na mesma proporÃ§Ã£o. 
    Esse Ã© o conceito de **O(n)**: o tempo de execuÃ§Ã£o aumenta linearmente com o tamanho da entrada. 
    O nÃºmero de operaÃ§Ãµes que o algoritmo realiza aumenta conforme o nÃºmero de itens que ele precisa processar.
    
- **ğŸ§ Exemplo PrÃ¡tico**
    
    Passo a passo:
    
    1. VocÃª tem um array de 10 elementos e quer somar todos os nÃºmeros nele.
    2. VocÃª comeÃ§a do primeiro elemento e vai atÃ© o Ãºltimo, somando um por um.
    3. O nÃºmero de passos (operaÃ§Ãµes) que o algoritmo faz Ã© igual ao nÃºmero de elementos no array.
    4. Portanto, se o array tiver 100 elementos, o algoritmo farÃ¡ 100 operaÃ§Ãµes; se tiver 1.000, ele farÃ¡ 1.000 operaÃ§Ãµes.
    
    **Outro exemplo:**
    
    - **Buscar um elemento em um array nÃ£o ordenado**: O algoritmo precisa olhar cada elemento atÃ© encontrar o que estÃ¡ procurando.
    - **Imprimir todos os elementos de um array**: O tempo de execuÃ§Ã£o aumenta com o nÃºmero de elementos que vocÃª precisa imprimir.
- **â° Sobre Complexidade Temporal**
    
    **O(n)** Ã© linear. O tempo de execuÃ§Ã£o cresce na mesma proporÃ§Ã£o que o tamanho da entrada. 
    Se vocÃª tem 1.000 itens para processar, o algoritmo farÃ¡ 1.000 operaÃ§Ãµes, e se vocÃª tiver 10.000 itens, farÃ¡ 10.000 operaÃ§Ãµes.
    
    â° **Exemplos de O(n) - Temporal**
    
    - **Soma de todos os elementos de um array**: O algoritmo percorre cada elemento uma vez para somÃ¡-los.
    - **Buscar um item em um array nÃ£o ordenado**: O algoritmo verifica cada elemento atÃ© encontrar o item.
    - **Imprimir cada valor de uma lista**: A operaÃ§Ã£o de imprimir cada item exige uma operaÃ§Ã£o por item na lista.
- **ğŸ‘©ğŸ¼â€ğŸš€ Sobre Complexidade Espacial**
    - **Armazenar cÃ³pias dos elementos de uma lista**: Se o algoritmo precisa criar uma nova lista para armazenar os elementos, o espaÃ§o necessÃ¡rio cresce com o nÃºmero de elementos.
    - **Contar o nÃºmero de vezes que um valor aparece em um array**: Para cada item que o algoritmo verifica, ele precisa de um pouco mais de memÃ³ria para armazenar a contagem.
- **ğŸ” Como identificar se Ã© O(n)?**
    
    **Como identificar**:
    
    Se o algoritmo faz uma operaÃ§Ã£o para cada item na entrada (ou em uma parte significativa da entrada), o tempo de execuÃ§Ã£o Ã© **O(n)**. O nÃºmero de operaÃ§Ãµes cresce proporcionalmente ao tamanho da entrada.
    
    **Exemplo**:
    
    - Se vocÃª precisa percorrer uma lista e realizar uma operaÃ§Ã£o em cada item (como somar ou verificar um valor), isso serÃ¡ **O(n)** porque o nÃºmero de operaÃ§Ãµes aumenta conforme o tamanho da lista.

---

## **O(n log n) â€“ Complexidade Quasilinear â†’**

> *"Organizar um baralho dividindo as cartas em pilhas menores e juntando depois."*
> 
- **ğŸ§  Explicado usando a TÃ©cnica Feynman**
    
    Imagine que vocÃª tem um grande nÃºmero de dados e quer organizÃ¡-los de alguma forma, como em um array. Agora, em vez de olhar para todos os dados de uma vez, vocÃª divide em partes menores e faz algo com essas partes (como ordenÃ¡-las) para depois juntar tudo de novo. 
    Esse processo de dividir, ordenar e juntar faz o tempo de execuÃ§Ã£o crescer de maneira um pouco mais complexa do que um simples **O(n)**, mas muito mais rÃ¡pido do que o **O(nÂ²)**. 
    
    O "log n" vem do processo de dividir repetidamente os dados em partes menores, e o "n" vem de ter que processar todos os dados ao longo do caminho.
    
- **ğŸ§ Exemplo PrÃ¡tico**
    - Exemplos de algoritmos que usam:
        - ORDENAÃ‡ÃƒO (quicksort, mergesort)
        - DIVIDIR E CONQUISTAR
    - Digamos que vocÃª tenha um array de **n** elementos.
    - VocÃª divide esse array em dois subarrays menores atÃ© que cada subarray tenha um Ãºnico elemento.
    - Depois, vocÃª comeÃ§a a juntar esses subarrays ordenando-os, de forma que no final vocÃª tenha o array inteiro ordenado.
    - O tempo para dividir os arrays Ã© **O(log n)**, e o tempo para percorrer todos os **n** elementos enquanto vocÃª faz a ordenaÃ§Ã£o Ã© **O(n)**.
    - Juntando os dois, temos **O(n log n)**.
- **â° Sobre Complexidade Temporal**
    
    **O(n log n)** significa que o tempo de execuÃ§Ã£o aumenta conforme o nÃºmero de elementos cresce, mas de uma forma mais controlada do que **O(nÂ²)**. 
    
    A ordem de grandeza do tempo de execuÃ§Ã£o Ã© mais eficiente, o que faz esse tipo de algoritmo ser muito Ãºtil para problemas grandes, como ordenaÃ§Ã£o de dados.
    
    â° **Exemplos de O(n log n) - Temporal**
    
    - **Merge Sort**: Um dos algoritmos mais conhecidos para ordenar dados com **O(n log n)**.
    - **Quick Sort**: Outro algoritmo de ordenaÃ§Ã£o que tem um desempenho de **O(n log n)**, mas em alguns casos pode ter desempenho pior se nÃ£o for bem implementado.
- **ğŸ‘©ğŸ¼â€ğŸš€ Sobre Complexidade Espacial**
    
    **O(n log n)** pode envolver o uso de memÃ³ria extra para armazenar os subarrays temporÃ¡rios durante o processo de divisÃ£o e junÃ§Ã£o. 
    Dependendo do algoritmo, pode ser necessÃ¡rio mais espaÃ§o para armazenar esses dados temporÃ¡rios.
    
    ğŸ’¾ **Exemplos de O(n log n) - Espacial**
    
    - **Merge Sort**: Durante o processo de ordenaÃ§Ã£o, o **Merge Sort** precisa de espaÃ§o extra proporcional a **O(n)** para armazenar subarrays temporÃ¡rios.
    - **Quick Sort**: O espaÃ§o extra usado pelo **Quick Sort** pode ser **O(log n)** no melhor caso, mas pode ser maior dependendo de como a recursÃ£o Ã© realizada.
- **ğŸ” Como identificar se Ã© O(n log n)?**
    - Para identificar se um algoritmo tem **O(n log n)** de complexidade, Ã© importante procurar por processos que envolvem dividir um conjunto de dados em partes menores e realizar uma operaÃ§Ã£o sobre cada uma dessas partes, como ordenar. 
    Esses algoritmos tendem a ter uma combinaÃ§Ã£o de um loop que percorre todos os **n** dados e um processo de divisÃ£o recursiva ou logarÃ­tmica.
    
    **Como identificar:**
    
    1. Se vocÃª vÃª uma **divisÃ£o repetitiva** dos dados, como no caso de **Merge Sort** ou **Quick Sort**.
    2. Se cada operaÃ§Ã£o de divisÃ£o tem um custo de **O(log n)**, mas vocÃª ainda precisa passar por todos os dados **n**.
    3. Quando o tempo de execuÃ§Ã£o Ã© uma combinaÃ§Ã£o de linear e logarÃ­tmica, como **n log n**.

---

## **O(nÂ²) â€“ Complexidade QuadrÃ¡tica â†’**

> *"Comparar cada aluno da turma com todos os outros para descobrir quem Ã© mais alto."*
> 
- **ğŸ§  Explicado usando a TÃ©cnica Feynman**
    
    **Viu loop dentro de um loop ou Bubble sort? Pode cravar que Ã© O(nÂ²)!**
    Imagine que vocÃª tem uma lista de pessoas e quer comparar cada uma delas com todas as outras para encontrar pares com algo em comum. No comeÃ§o, vocÃª compara a primeira pessoa com todas as outras, depois a segunda com todas as outras (exceto a primeira, porque jÃ¡ foi comparada), e assim por diante. 
    Isso cria uma cascata de comparaÃ§Ãµes, onde cada novo elemento faz o nÃºmero de interaÃ§Ãµes crescer de forma quadrÃ¡tica. Se tivermos 10 elementos, fazemos **100 comparaÃ§Ãµes**; se tivermos 1.000, fazemos **1.000.000**! 
    Isso explica por que algoritmos **O(nÂ²)** ficam lentos com entradas grandes.
    
- **ğŸ§ Exemplo PrÃ¡tico**
    - VocÃª tem um array de **n** elementos.
    - VocÃª precisa comparar cada elemento com todos os outros.
    - O primeiro elemento serÃ¡ comparado com **n - 1** elementos.
    - O segundo elemento serÃ¡ comparado com **n - 2** elementos.
    - Isso se repete atÃ© o Ãºltimo elemento, criando **n Ã— n** operaÃ§Ãµes.
- **â° Sobre Complexidade Temporal**
    
    **O(nÂ²)** significa que Ã  medida que **n** cresce, o tempo de execuÃ§Ã£o cresce proporcionalmente ao quadrado desse nÃºmero. 
    Isso significa que um pequeno aumento no tamanho do input pode resultar em um aumento **exponencial** no tempo de execuÃ§Ã£o.
    
    â° **Exemplos de O(nÂ²) - Temporal**
    
    - **Bubble Sort**: Cada elemento precisa ser comparado com todos os outros.
    - **Selection Sort**: Busca pelo menor elemento e o troca de posiÃ§Ã£o vÃ¡rias vezes.
    - **Algoritmo ingÃªnuo para encontrar pares duplicados**: Um loop dentro de outro loop para verificar se existem elementos iguais.
- **ğŸ‘©ğŸ¼â€ğŸš€ Sobre Complexidade Espacial**
    
    **O(nÂ²)** pode, em alguns casos, exigir uma grande quantidade de memÃ³ria extra se for necessÃ¡rio armazenar pares, matrizes ou listas auxiliares durante as operaÃ§Ãµes.
    
    ğŸ’¾ **Exemplos de O(nÂ²) - Espacial**
    
    - **MultiplicaÃ§Ã£o de Matrizes IngÃªnua**: Cada cÃ©lula da matriz resultante requer mÃºltiplas iteraÃ§Ãµes pelos dados.
    - **CriaÃ§Ã£o de tabelas auxiliares** para armazenar relaÃ§Ãµes entre elementos (exemplo: uma tabela de adjacÃªncia em grafos).
- **ğŸ” Como identificar se Ã© O(nÂ²)?**
    - Para identificar se um algoritmo tem **O(nÂ²)** de complexidade, procure por **loops aninhados** onde cada iteraÃ§Ã£o percorre toda a entrada para cada elemento.
    
    **Como identificar:**
    
    1. Se hÃ¡ **dois loops aninhados** que percorrem o mesmo conjunto de dados.
    2. Se a quantidade de operaÃ§Ãµes cresce **muito rÃ¡pido** conforme o input aumenta.
    3. Se um problema envolve comparar **todos os elementos com todos os outros** (como em alguns algoritmos de ordenaÃ§Ã£o).

---

# Outras notaÃ§Ãµes do BIG O (menos comuns):

## **O(2â¿) â€“ Complexidade Exponencial â†’**

> *"Testar todas as formas possÃ­veis de resolver um cubo mÃ¡gico."*
> 
- **ğŸ§  Explicado usando a TÃ©cnica Feynman**
    
    Imagine que vocÃª tem um cofre e quer descobrir a senha, mas nÃ£o sabe quantos nÃºmeros precisa testar. 
    
    Cada vez que vocÃª adiciona um dÃ­gito a mais, o nÃºmero de possibilidades dobra. Se a senha tiver 1 dÃ­gito, hÃ¡ 2 possibilidades (0 ou 1). 
    
    Se tiver 2 dÃ­gitos, hÃ¡ 4 possibilidades (00, 01, 10, 11). Com 3 dÃ­gitos, jÃ¡ sÃ£o 8 possibilidades. 
    
    Assim, conforme o nÃºmero de elementos aumenta, o nÃºmero de operaÃ§Ãµes cresce exponencialmente, dobrando a cada nova unidade adicionada.
    
- **ğŸ§ Exemplo PrÃ¡tico**
    - VocÃª precisa gerar **todas as combinaÃ§Ãµes possÃ­veis** de um conjunto.
    - Se hÃ¡ **n elementos**, cada um pode estar **presente ou ausente** na combinaÃ§Ã£o.
    - Isso cria **2â¿ possibilidades** de subconjuntos.
    - Para **n = 3**, as combinaÃ§Ãµes possÃ­veis seriam:
        - `{}`
        - `{A}`
        - `{B}`
        - `{C}`
        - `{A, B}`
        - `{A, C}`
        - `{B, C}`
        - `{A, B, C}`
    - Para **n = 4**, jÃ¡ terÃ­amos **16 possibilidades**.
    - Para **n = 10**, jÃ¡ seriam **1024 possibilidades**. ğŸ˜¯
- **â° Sobre Complexidade Temporal**
    
    **O(2â¿)** significa que, conforme o input cresce, o tempo de execuÃ§Ã£o **dobra** a cada novo elemento. Isso torna esses algoritmos extremamente ineficientes para inputs grandes.
    
    â° **Exemplos de O(2â¿) - Temporal**
    
    - **Problema do subconjunto**: Gerar todas as combinaÃ§Ãµes possÃ­veis de um conjunto.
    - **Problema da Mochila (ForÃ§a Bruta)**: Testar todas as combinaÃ§Ãµes possÃ­veis de itens para encontrar o melhor conjunto.
    - **Fibonacci Recursivo (sem otimizaÃ§Ã£o)**: A versÃ£o ingÃªnua da sequÃªncia de Fibonacci, onde cada chamada recursiva cria duas novas chamadas.
- **ğŸ‘©ğŸ¼â€ğŸš€ Sobre Complexidade Espacial**
    
    **O(2â¿)** pode exigir **muito espaÃ§o na memÃ³ria**, especialmente quando todas as possibilidades precisam ser armazenadas antes da execuÃ§Ã£o.
    
    ğŸ’¾ **Exemplos de O(2â¿) - Espacial**
    
    - **Armazenamento de todas as combinaÃ§Ãµes de um conjunto**.
    - **Backtracking em problemas de busca exaustiva**, onde todas as opÃ§Ãµes precisam ser mantidas na pilha de chamadas da recursÃ£o.
- **ğŸ” Como identificar se Ã© O(2â¿)?**
    - Se o nÃºmero de operaÃ§Ãµes **dobra** a cada novo elemento adicionado, vocÃª provavelmente estÃ¡ lidando com **O(2â¿)**.
    
    **Como identificar:**
    
    1. Se o algoritmo envolve **gerar todas as combinaÃ§Ãµes possÃ­veis** de um conjunto.
    2. Se a soluÃ§Ã£o usa **recursÃ£o exponencial**, onde cada chamada gera **duas ou mais chamadas recursivas**.
    3. Se a quantidade de operaÃ§Ãµes cresce **extremamente rÃ¡pido**, tornando o algoritmo inviÃ¡vel para inputs grandes.

---

## **O(âˆšn) â€“ Complexidade de Raiz Quadrada â†’**

> *"Subir uma escada pulando degraus para chegar mais rÃ¡pido ao topo."*
> 
- **ğŸ§  Explicado usando a TÃ©cnica Feynman**
    
    Imagine que vocÃª precisa encontrar um nÃºmero especÃ­fico dentro de **n** elementos, mas, ao invÃ©s de verificar todos um por um (**O(n)**), vocÃª pode **pular** de um grupo para outro, reduzindo drasticamente a quantidade de verificaÃ§Ãµes. 
    Por exemplo, se vocÃª tivesse **100 elementos**, ao invÃ©s de checar todos, vocÃª poderia **dividir em blocos** e testar apenas **âˆš100 = 10 elementos**. 
    Esse comportamento aparece em problemas onde Ã© possÃ­vel reduzir a busca para a raiz quadrada do input.
    
- **ğŸ§ Exemplo PrÃ¡tico**
    - VocÃª precisa encontrar um nÃºmero **primo** menor que **n**.
    - Ao invÃ©s de testar divisibilidade atÃ© **n**, vocÃª sÃ³ precisa verificar atÃ© **âˆšn**.
    - Exemplo: Para verificar se **37 Ã© primo**, vocÃª nÃ£o precisa testar divisibilidade por todos os nÃºmeros atÃ© 37, basta testar atÃ© **âˆš37 â‰ˆ 6**.
    - Se nenhum nÃºmero atÃ© 6 divide 37, entÃ£o 37 Ã© primo.
- **â° Sobre Complexidade Temporal**
    
    **O(âˆšn)** significa que o tempo de execuÃ§Ã£o cresce com a raiz quadrada do tamanho da entrada. 
    Isso Ã© mais eficiente que **O(n)** para entradas grandes.
    
    â° **Exemplos de O(âˆšn) - Temporal**
    
    - **VerificaÃ§Ã£o de primalidade**: Testar se um nÃºmero Ã© primo.
    - **Encontrar todos os divisores de um nÃºmero**: VocÃª sÃ³ precisa testar atÃ© a raiz quadrada do nÃºmero.
- **ğŸ‘©ğŸ¼â€ğŸš€ Sobre Complexidade Espacial**
    
    **O(âˆšn)** geralmente nÃ£o requer muito espaÃ§o adicional, pois a maioria das operaÃ§Ãµes pode ser feita in-place.
    
    ğŸ’¾ **Exemplos de O(âˆšn) - Espacial**
    
    - **Armazenamento de divisores**: Em alguns casos, vocÃª pode precisar armazenar os divisores encontrados.
    - **Buffer temporÃ¡rio**: Para algumas operaÃ§Ãµes matemÃ¡ticas que trabalham com blocos de tamanho âˆšn.
- **ğŸ” Como identificar se Ã© O(âˆšn)?**
    
    **Como identificar:**
    
    1. Se o algoritmo trabalha com **blocos** ou **grupos** de tamanho âˆšn.
    2. Se envolve **operaÃ§Ãµes matemÃ¡ticas** onde vocÃª sÃ³ precisa verificar atÃ© a raiz quadrada do nÃºmero.
    3. Se hÃ¡ uma **otimizaÃ§Ã£o** que permite pular verificaÃ§Ãµes baseada na raiz quadrada do tamanho da entrada.